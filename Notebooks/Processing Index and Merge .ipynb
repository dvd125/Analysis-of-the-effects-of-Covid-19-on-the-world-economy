{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing e Merge dei dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Daily_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>000001.SS</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>2921.397949</td>\n",
       "      <td>0.204671</td>\n",
       "      <td>84161.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan</td>\n",
       "      <td>^N225</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>22325.609375</td>\n",
       "      <td>1.193065</td>\n",
       "      <td>16837.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>^GDAXI</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>12021.280273</td>\n",
       "      <td>3.749342</td>\n",
       "      <td>183879.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>^NYA</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>12046.410156</td>\n",
       "      <td>1.228294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>^TASI-SR</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>7285.230000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>89011.0</td>\n",
       "      <td>1869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>^MERV</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>41106.968750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>Spain</td>\n",
       "      <td>^IBEX</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>9691.200195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>Canada</td>\n",
       "      <td>^GSPTSE</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>17100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>^FTSE</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>7604.299805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>Germany</td>\n",
       "      <td>^GDAXI</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>13385.929688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1760 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Country     Symbol       Date         Close      Rate  Confirmed  \\\n",
       "0              China  000001.SS 2020-06-02   2921.397949  0.204671    84161.0   \n",
       "1              Japan      ^N225 2020-06-02  22325.609375  1.193065    16837.0   \n",
       "2            Germany     ^GDAXI 2020-06-02  12021.280273  3.749342   183879.0   \n",
       "3                 US       ^NYA 2020-06-02  12046.410156  1.228294        0.0   \n",
       "4       Saudi Arabia   ^TASI-SR 2020-06-02   7285.230000 -0.050000    89011.0   \n",
       "...              ...        ...        ...           ...       ...        ...   \n",
       "1755       Argentina      ^MERV 2020-01-02  41106.968750  0.000000        0.0   \n",
       "1756           Spain      ^IBEX 2020-01-02   9691.200195  0.000000        0.0   \n",
       "1757          Canada    ^GSPTSE 2020-01-02  17100.000000  0.000000        0.0   \n",
       "1758  United Kingdom      ^FTSE 2020-01-02   7604.299805  0.000000        0.0   \n",
       "1759         Germany     ^GDAXI 2020-01-02  13385.929688  0.000000        0.0   \n",
       "\n",
       "      Daily_confirmed  \n",
       "0                 7.0  \n",
       "1                50.0  \n",
       "2               285.0  \n",
       "3                 0.0  \n",
       "4              1869.0  \n",
       "...               ...  \n",
       "1755              0.0  \n",
       "1756              0.0  \n",
       "1757              0.0  \n",
       "1758              0.0  \n",
       "1759              0.0  \n",
       "\n",
       "[1760 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as dd\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "client=MongoClient()\n",
    "db=client.dataman\n",
    "alpha = db.alpha\n",
    "#scegliamo di filtrare le serie storiche per il lasso di tempo relativo al primo semestre del 2020\n",
    "start = dt.datetime(2020,1,2)\n",
    "end = dt.datetime(2020,6,2)\n",
    "#importiamo i dati del covid da mongo su python\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "client=MongoClient()\n",
    "db=client.dataman\n",
    "covid = db.covid\n",
    "c19 = pd.DataFrame(list(covid.find()))\n",
    "del c19['_id']\n",
    "#utilizziamo un mask per poter selezionare i dati di interesse relativi al primo semestre\n",
    "mask = (c19['Date'] > '2020-01-22') & (c19['Date'] <= '2020-06-02')\n",
    "covid_19 = c19.loc[mask].reset_index()\n",
    "del covid_19['index']\n",
    "covid_19\n",
    "\n",
    "# Francia\n",
    "\n",
    "#import serie storica indice da yahoo finance\n",
    "cac40 = dd.DataReader('^FCHI', 'yahoo', start, end)\n",
    "cac40= cac40.reset_index()\n",
    "cac40['Date']=cac40['Date'].astype(str)\n",
    "cac40['Date'] = pd.to_datetime(cac40['Date'], format='%Y-%m-%d')\n",
    "cac40['Symbol']= '^FCHI'\n",
    "cac40['Country']= 'France'\n",
    "#aggiungiamo la colonna Rate per poter calcolare ed inserire le variazioni percentuali degli indici\n",
    "cac40['Rate']=0\n",
    "i=0\n",
    "for i in range (len(cac40.Close)-1):\n",
    "     cac40.Rate.loc[i+1]=((cac40['Close'].loc[i+1]-cac40['Close'].loc[i])/cac40['Close'].loc[i])*100\n",
    "#filtriamo il dataframe eliminando le colonne che non interessano\n",
    "cac40= cac40.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='France')\n",
    "c_fr = covid_19.loc[mask].reset_index()\n",
    "del c_fr['index']\n",
    "#calcoliamo il numero di aumento dei contaggi giornalieri\n",
    "c_fr['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_fr.Confirmed)-1):\n",
    "    c_fr.Daily_confirmed.loc[i]=((c_fr['Confirmed'].loc[i]-c_fr['Confirmed'].loc[i+1]))\n",
    "\n",
    "i=1\n",
    "for i in range (1,len(c_fr.Daily_confirmed)-1):\n",
    "    if c_fr.Daily_confirmed[i]<0:\n",
    "        c_fr.Daily_confirmed[i]=(c_fr.Daily_confirmed[i+1]+c_fr.Daily_confirmed[i-1])/2\n",
    "    else:\n",
    "            continue\n",
    "c_fr.Daily_confirmed = c_fr.Daily_confirmed.astype(int)\n",
    "g= pd.merge(cac40,c_fr,on=['Date','Country'],how='outer')\n",
    "france=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#Germania\n",
    "mask = (covid_19['Country']=='Germany')\n",
    "c_germany = covid_19.loc[mask].reset_index()\n",
    "del c_germany['index']\n",
    "dax = dd.DataReader('^GDAXI', 'yahoo', start, end)\n",
    "dax= dax.reset_index()\n",
    "dax['Date']=dax['Date'].astype(str)\n",
    "dax['Date'] = pd.to_datetime(dax['Date'], format='%Y-%m-%d')\n",
    "dax['Symbol']= '^GDAXI'\n",
    "dax['Country']= 'Germany'\n",
    "dax['Rate']=0\n",
    "i=0\n",
    "for i in range (len(dax.Close)-1):\n",
    "     dax.Rate.loc[i+1]=((dax['Close'].loc[i+1]-dax['Close'].loc[i])/dax['Close'].loc[i])*100\n",
    "        \n",
    "dax= dax.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "c_germany['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_germany.Confirmed)-1):\n",
    "    c_germany.Daily_confirmed.loc[i]=((c_germany['Confirmed'].loc[i]-c_germany['Confirmed'].loc[i+1]))\n",
    "g= pd.merge(dax,c_germany,on=['Date','Country'],how='outer')\n",
    "germany=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#Giappone\n",
    "nikkei = dd.DataReader('^N225', 'yahoo', start, end)\n",
    "nikkei= nikkei.reset_index()\n",
    "nikkei['Date']=nikkei['Date'].astype(str)\n",
    "nikkei['Date'] = pd.to_datetime(nikkei['Date'], format='%Y-%m-%d')\n",
    "nikkei['Symbol']= '^N225'\n",
    "nikkei['Country']= 'Japan'\n",
    "nikkei['Rate']=0\n",
    "i=0\n",
    "for i in range (len(nikkei.Close)-1):\n",
    "     nikkei.Rate.loc[i+1]=((nikkei['Close'].loc[i+1]-nikkei['Close'].loc[i])/nikkei['Close'].loc[i])*100\n",
    "nikkei= nikkei.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Japan')\n",
    "covid_jp = covid_19.loc[mask].reset_index()\n",
    "del covid_jp['index']\n",
    "c_jp=covid_jp.sort_values(by=['Date'],ascending=True)\n",
    "c_jp['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_jp.Confirmed)-1):\n",
    "    c_jp.Daily_confirmed.loc[i]=((c_jp['Confirmed'].loc[i]-c_jp['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(nikkei,c_jp,on=['Date','Country'],how='outer')\n",
    "japan=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "\n",
    "#Spagna\n",
    "ibex = dd.DataReader('^IBEX', 'yahoo', start, end)\n",
    "ibex= ibex.reset_index()\n",
    "ibex['Date']=ibex['Date'].astype(str)\n",
    "ibex['Date'] = pd.to_datetime(ibex['Date'], format='%Y-%m-%d')\n",
    "ibex['Symbol']= '^IBEX'\n",
    "ibex['Country']= 'Spain'\n",
    "ibex['Rate']=0\n",
    "i=0\n",
    "for i in range (len(ibex.Close)-1):\n",
    "     ibex.Rate.loc[i+1]=((ibex['Close'].loc[i+1]-ibex['Close'].loc[i])/ibex['Close'].loc[i])*100\n",
    "ibex= ibex.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Spain')\n",
    "c_sp = covid_19.loc[mask].reset_index()\n",
    "del c_sp['index']\n",
    "c_sp['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_sp.Confirmed)-1):\n",
    "    c_sp.Daily_confirmed.loc[i]=((c_sp['Confirmed'].loc[i]-c_sp['Confirmed'].loc[i+1]))\n",
    "\n",
    "i=1\n",
    "for i in range (len(c_sp.Daily_confirmed)-1):\n",
    "    if c_sp.Daily_confirmed[i]<0:\n",
    "        c_sp.Daily_confirmed[i]=(c_sp.Daily_confirmed[i+1]+c_sp.Daily_confirmed[i-1])/2\n",
    "    else:\n",
    "            continue\n",
    "            \n",
    "g= pd.merge(ibex,c_sp,on=['Date','Country'],how='outer')\n",
    "spain=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#Australia\n",
    "axjo = dd.DataReader('^AXJO', 'yahoo', start, end)\n",
    "axjo= axjo.reset_index()\n",
    "axjo['Date']=axjo['Date'].astype(str)\n",
    "axjo['Date'] = pd.to_datetime(axjo['Date'], format='%Y-%m-%d')\n",
    "axjo['Symbol']= '^AXJO'\n",
    "axjo['Country']= 'Australia'\n",
    "axjo['Rate']=0\n",
    "i=0\n",
    "for i in range (len(axjo.Close)-1):\n",
    "     axjo.Rate.loc[i+1]=((axjo['Close'].loc[i+1]-axjo['Close'].loc[i])/axjo['Close'].loc[i])*100\n",
    "axjo= axjo.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Australia')\n",
    "covid_as = covid_19.loc[mask].reset_index()\n",
    "del covid_as['index']\n",
    "c_as=covid_as.sort_values(by=['Date'],ascending=True)\n",
    "c_as['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_as.Confirmed)-1):\n",
    "    c_as.Daily_confirmed.loc[i]=((c_as['Confirmed'].loc[i]-c_as['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(axjo,c_as,on=['Date','Country'],how='outer')\n",
    "australia=g[g['Close'].notna()].fillna(0).loc[:105].reset_index(drop=True)\n",
    "\n",
    "#Argentina\n",
    "merv = dd.DataReader('^MERV', 'yahoo', start, end)\n",
    "merv= merv.reset_index()\n",
    "merv['Date']=merv['Date'].astype(str)\n",
    "merv['Date'] = pd.to_datetime(merv['Date'], format='%Y-%m-%d')\n",
    "merv['Symbol']= '^MERV'\n",
    "merv['Country']= 'Argentina'\n",
    "merv['Rate']=0\n",
    "i=0\n",
    "for i in range (len(merv.Close)-1):\n",
    "     merv.Rate.loc[i+1]=((merv['Close'].loc[i+1]-merv['Close'].loc[i])/merv['Close'].loc[i])*100\n",
    "merv= merv.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Argentina')\n",
    "c_argentina = covid_19.loc[mask].reset_index()\n",
    "del c_argentina['index']\n",
    "c_argentina['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_argentina.Confirmed)-1):\n",
    "    c_argentina.Daily_confirmed.loc[i]=((c_argentina['Confirmed'].loc[i]-c_argentina['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(merv,c_argentina,on=['Date','Country'],how='outer')\n",
    "argentina=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#Stati Uniti d'America\n",
    "nya = dd.DataReader('^NYA', 'yahoo', start, end)\n",
    "nya= nya.reset_index()\n",
    "nya['Date']=nya['Date'].astype(str)\n",
    "nya['Date'] = pd.to_datetime(nya['Date'], format='%Y-%m-%d')\n",
    "nya['Symbol']= '^NYA'\n",
    "nya['Country']= 'US'\n",
    "nya['Rate']=0\n",
    "i=0\n",
    "for i in range (len(nya.Close)-1):\n",
    "     nya.Rate.loc[i+1]=((nya['Close'].loc[i+1]-nya['Close'].loc[i])/nya['Close'].loc[i])*100\n",
    "nya= nya.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Us')\n",
    "covid_us = covid_19.loc[mask].reset_index()\n",
    "del covid_us['index']\n",
    "c_us=covid_us.sort_values(by=['Date'],ascending=True)\n",
    "c_us['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_us.Confirmed)-1):\n",
    "    c_us.Daily_confirmed.loc[i]=((c_us['Confirmed'].loc[i]-c_us['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(nya,c_us,on=['Date','Country'],how='outer')\n",
    "us=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#Canada\n",
    "gsptse = dd.DataReader('^GSPTSE', 'yahoo', start, end)\n",
    "gsptse= gsptse.reset_index()\n",
    "gsptse['Date']=gsptse['Date'].astype(str)\n",
    "gsptse['Date'] = pd.to_datetime(gsptse['Date'], format='%Y-%m-%d')\n",
    "gsptse['Symbol']= '^GSPTSE'\n",
    "gsptse['Country']= 'Canada'\n",
    "gsptse['Rate']=0\n",
    "i=0\n",
    "for i in range (len(gsptse.Close)-1):\n",
    "     gsptse.Rate.loc[i+1]=((gsptse['Close'].loc[i+1]-gsptse['Close'].loc[i])/gsptse['Close'].loc[i])*100\n",
    "gsptse= gsptse.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Canada')\n",
    "covid_ca = covid_19.loc[mask].reset_index()\n",
    "del covid_ca['index']\n",
    "c_ca=covid_ca.sort_values(by=['Date'],ascending=True)\n",
    "c_ca['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_ca.Confirmed)-1):\n",
    "    c_ca.Daily_confirmed.loc[i]=((c_ca['Confirmed'].loc[i]-c_ca['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(gsptse,c_ca,on=['Date','Country'],how='outer')\n",
    "canada=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#India\n",
    "bsesn = dd.DataReader('^BSESN', 'yahoo', start, end)\n",
    "bsesn= bsesn.reset_index()\n",
    "bsesn['Date']=bsesn['Date'].astype(str)\n",
    "bsesn['Date'] = pd.to_datetime(bsesn['Date'], format='%Y-%m-%d')\n",
    "bsesn['Symbol']= '^BSESN'\n",
    "bsesn['Country']= 'India'\n",
    "bsesn['Rate']=0\n",
    "i=0\n",
    "for i in range (len(bsesn.Close)-1):\n",
    "     bsesn.Rate.loc[i+1]=((bsesn['Close'].loc[i+1]-bsesn['Close'].loc[i])/bsesn['Close'].loc[i])*100\n",
    "bsesn= bsesn.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='India')\n",
    "covid_in = covid_19.loc[mask].reset_index()\n",
    "del covid_in['index']\n",
    "c_in=covid_in.sort_values(by=['Date'],ascending=True)\n",
    "c_in['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_in.Confirmed)-1):\n",
    "    c_in.Daily_confirmed.loc[i]=((c_in['Confirmed'].loc[i]-c_in['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(bsesn,c_in,on=['Date','Country'],how='outer')\n",
    "india=g[g['Close'].notna()].fillna(0)\n",
    "#Cina\n",
    "sse = dd.DataReader('000001.SS','yahoo',start,end)\n",
    "sse= sse.reset_index()\n",
    "sse['Date']=sse['Date'].astype(str)\n",
    "sse['Date'] = pd.to_datetime(sse['Date'], format='%Y-%m-%d')\n",
    "sse['Symbol']= '000001.SS'\n",
    "sse['Country']= 'China'\n",
    "sse['Rate']=0\n",
    "i=0\n",
    "for i in range (len(sse.Close)-1):\n",
    "     sse.Rate.loc[i+1]=((sse['Close'].loc[i+1]-sse['Close'].loc[i])/sse['Close'].loc[i])*100\n",
    "sse= sse.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='China')\n",
    "covid_ch = covid_19.loc[mask].reset_index()\n",
    "del covid_ch['index']\n",
    "c_ch=covid_ch.sort_values(by=['Date'],ascending=True)\n",
    "c_ch['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_ch.Confirmed)-1):\n",
    "    c_ch.Daily_confirmed.loc[i]=((c_ch['Confirmed'].loc[i]-c_ch['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(sse,c_ch,on=['Date','Country'],how='outer')\n",
    "china=g[g['Close'].notna()].fillna(0).loc[:98].reset_index(drop=True)\n",
    "#Brasile\n",
    "bvsp = dd.DataReader('^BVSP','yahoo',start,end)\n",
    "bvsp= bvsp.reset_index()\n",
    "bvsp['Date']=bvsp['Date'].astype(str)\n",
    "bvsp['Date'] = pd.to_datetime(bvsp['Date'], format='%Y-%m-%d')\n",
    "bvsp['Symbol']= '^BVSP'\n",
    "bvsp['Country']= 'Brazil'\n",
    "bvsp['Rate']=0\n",
    "i=0\n",
    "for i in range (len(bvsp.Close)-1):\n",
    "     bvsp.Rate.loc[i+1]=((bvsp['Close'].loc[i+1]-bvsp['Close'].loc[i])/bvsp['Close'].loc[i])*100\n",
    "bvsp= bvsp.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Brazil')\n",
    "covid_bz = covid_19.loc[mask].reset_index()\n",
    "del covid_bz['index']\n",
    "c_bz=covid_bz.sort_values(by=['Date'],ascending=True)\n",
    "c_bz['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_bz.Confirmed)-1):\n",
    "    c_bz.Daily_confirmed.loc[i]=((c_bz['Confirmed'].loc[i]-c_bz['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(bvsp,c_bz,on=['Date','Country'],how='outer')\n",
    "brazil=g[g['Close'].notna()].fillna(0)\n",
    "#Corea del Sud\n",
    "kospi = dd.DataReader('^KS11','yahoo',start,end)\n",
    "kospi= kospi.reset_index()\n",
    "kospi['Date']=kospi['Date'].astype(str)\n",
    "kospi['Date'] = pd.to_datetime(kospi['Date'], format='%Y-%m-%d')\n",
    "kospi['Symbol']= '^KS11'\n",
    "kospi['Country']= 'Korea, South'\n",
    "kospi['Rate']=0\n",
    "kospi= kospi.drop([103])\n",
    "i=0\n",
    "for i in range (len(kospi.Close)-1):\n",
    "     kospi.Rate.loc[i+1]=((kospi['Close'].loc[i+1]-kospi['Close'].loc[i])/kospi['Close'].loc[i])*100\n",
    "kospi= kospi.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Korea, South')\n",
    "covid_ks = covid_19.loc[mask].reset_index()\n",
    "del covid_ks['index']\n",
    "c_ks=covid_ks.sort_values(by=['Date'],ascending=True)\n",
    "c_ks['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_ks.Confirmed)-1):\n",
    "    c_ks.Daily_confirmed.loc[i]=((c_ks['Confirmed'].loc[i]-c_ks['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(kospi,c_ks,on=['Date','Country'],how='outer')\n",
    "sk=g[g['Close'].notna()].fillna(0)\n",
    "#Russia\n",
    "moex = dd.DataReader('IMOEX.ME','yahoo',start,end)\n",
    "moex= moex.reset_index()\n",
    "moex['Date']=moex['Date'].astype(str)\n",
    "moex['Date'] = pd.to_datetime(moex['Date'], format='%Y-%m-%d')\n",
    "moex['Symbol']= 'IMOEX.ME'\n",
    "moex['Country']= 'Russia'\n",
    "moex['Rate']=0\n",
    "i=0\n",
    "for i in range (len(moex.Close)-1):\n",
    "     moex.Rate.loc[i+1]=((moex['Close'].loc[i+1]-moex['Close'].loc[i])/moex['Close'].loc[i])*100\n",
    "moex= moex.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='Russia')\n",
    "covid_rs = covid_19.loc[mask].reset_index()\n",
    "del covid_rs['index']\n",
    "c_rs=covid_rs.sort_values(by=['Date'],ascending=True)\n",
    "c_rs['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_rs.Confirmed)-1):\n",
    "    c_rs.Daily_confirmed.loc[i]=((c_rs['Confirmed'].loc[i]-c_rs['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(moex,c_rs,on=['Date','Country'],how='outer')\n",
    "russia=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#dataframe presi da investing.com, poichÃ¨ non reperibili su yahoo finance\n",
    "#dataframe che abbiamo controllato e che rispettano l'andamento dell'indici con piccole variazioni\n",
    "\n",
    "\n",
    "#Italia\n",
    "mib =pd.read_csv(r'C:\\Users\\ddoci\\Downloads\\MIB.csv')\n",
    "mib['Data']=mib['Data'].astype(str)\n",
    "mib['Data'] = pd.to_datetime(mib['Data'], format='%d.%m.%Y')\n",
    "mib['Data'] =  pd.to_datetime(mib['Data'], format='%Y.%m.%d')\n",
    "#rinominiamo le colonne cosicchÃ¨ rispettino lo stesso schema dei dataframe di yahoo finance\n",
    "mib.rename(columns={'Ultimo': 'Close', 'Apertura': 'Open','Massimo':'High','Minimo':'Low','Data':'Date'}, inplace=True)\n",
    "mib['Symbol']= 'FTSEMIB.MI'\n",
    "#modifichiamo i valori per far si che siano uguali a quelli di yahoo finance, eliminando il\".\" utilizzato come separatore\n",
    "#delle migliaia e sostituendo la \",\" con il \".\" per il separatore dei decimali\n",
    "mib['Close']=mib['Close'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "mib['Open']=mib['Open'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "mib['High']=mib['High'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "mib['Low']=mib['Low'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "mib['Rate']=mib['Var. %'].str.replace(',', '.').str.replace('%', '')\n",
    "mib['Country']='Italy'\n",
    "mi= mib.drop(columns =['Vol.','Open','High','Low','Var. %'])\n",
    "mi=mi.sort_values(by='Date').reset_index(drop=True)\n",
    "mask = (covid_19['Country']=='Italy')\n",
    "c_it = covid_19.loc[mask].reset_index()\n",
    "del c_it['index']\n",
    "c_it['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_it.Confirmed)-1):\n",
    "    c_it.Daily_confirmed.loc[i]=((c_it['Confirmed'].loc[i]-c_it['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(mi,c_it,on=['Date','Country'],how='outer')\n",
    "italy=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#Arabia Saudita\n",
    "tasi_ =pd.read_csv(r'C:\\Users\\ddoci\\Downloads\\TASI-SR.csv')\n",
    "tasi_['Data']=tasi_['Data'].astype(str)\n",
    "tasi_['Data'] = pd.to_datetime(tasi_['Data'], format='%d.%m.%Y')\n",
    "tasi_['Data'] =  pd.to_datetime(tasi_['Data'], format='%Y.%m.%d')\n",
    "tasi_.rename(columns={'Ultimo': 'Close', 'Apertura': 'Open','Massimo':'High','Minimo':'Low','Data':'Date'}, inplace=True)\n",
    "tasi_['Symbol']= '^TASI-SR'\n",
    "tasi_['Close']=tasi_['Close'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "tasi_['Rate']=tasi_['Var. %'].str.replace(',', '.').str.replace('%', '')\n",
    "tasi_['Country']='Saudi Arabia'\n",
    "tasi= tasi_.drop(columns =['Vol.','Open','High','Low','Var. %'])\n",
    "tasi=tasi.sort_values(by='Date').reset_index(drop=True)\n",
    "mask = (covid_19['Country']=='Saudi Arabia')\n",
    "covid_sa = covid_19.loc[mask].reset_index()\n",
    "del covid_sa['index']\n",
    "c_sa=covid_sa.sort_values(by=['Date'],ascending=True)\n",
    "c_sa['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_sa.Confirmed)-1):\n",
    "    c_sa.Daily_confirmed.loc[i]=((c_sa['Confirmed'].loc[i]-c_sa['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(tasi,c_sa,on=['Date','Country'],how='outer')\n",
    "sa=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#Turchia\n",
    "bist_ =pd.read_csv(r'C:\\Users\\ddoci\\Downloads\\BIST.csv')\n",
    "bist_['Data']=bist_['Data'].astype(str)\n",
    "bist_['Data'] = pd.to_datetime(bist_['Data'], format='%d.%m.%Y')\n",
    "bist_['Data'] = pd.to_datetime(bist_['Data'], format='%Y.%m.%d')\n",
    "bist= bist_.drop(columns =['Vol.'])\n",
    "bist_.rename(columns={'Ultimo': 'Close', 'Apertura': 'Open','Massimo':'High','Minimo':'Low','Data':'Date'}, inplace=True)\n",
    "bist_['Symbol']= '^BIST'\n",
    "bist_['Close']=bist_['Close'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "bist_['Rate']=bist_['Var. %'].str.replace(',', '.').str.replace('%', '')\n",
    "bist_['Country']='Turkey'\n",
    "bist= bist_.drop(columns =['Vol.','Open','High','Low','Var. %'])\n",
    "bist=bist.sort_values(by='Date').reset_index(drop=True)\n",
    "bist=bist.drop(bist.index[[104,105,106]])\n",
    "mask = (covid_19['Country']=='Turkey')\n",
    "c_ty = covid_19.loc[mask].reset_index()\n",
    "del c_ty['index']\n",
    "c_ty['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_ty.Confirmed)-1):\n",
    "    c_ty.Daily_confirmed.loc[i]=((c_ty['Confirmed'].loc[i]-c_ty['Confirmed'].loc[i+1]))\n",
    "    \n",
    "g= pd.merge(bist,c_ty,on=['Date','Country'],how='outer')\n",
    "turkey=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "\n",
    "#dataframe disponibile da yahoo finance solo se scaricato dal sito\n",
    "\n",
    "#Gran Bretagna\n",
    "ftse_=pd.read_csv(r'C:\\Users\\ddoci\\Downloads\\FTSE.csv')\n",
    "#filtriamo la tabella selezionando i dati relativi al primo semestre del 2020\n",
    "ftse=ftse_.loc[192:296].reset_index(drop=True)\n",
    "ftse['Date']=ftse['Date'].astype(str)\n",
    "ftse['Date'] = pd.to_datetime(ftse['Date'], format='%Y-%m-%d')\n",
    "ftse['Symbol']= '^FTSE'\n",
    "ftse['Country']= 'United Kingdom'\n",
    "ftse['Rate']=0\n",
    "i=0\n",
    "for i in range (len(ftse.Close)-1):\n",
    "     ftse.Rate.loc[i+1]=((ftse['Close'].loc[i+1]-ftse['Close'].loc[i])/ftse['Close'].loc[i])*100\n",
    "ftse= ftse.drop(columns =['High','Low','Open','Volume','Adj Close'])\n",
    "mask = (covid_19['Country']=='United Kingdom')\n",
    "c_uk= covid_19.loc[mask].reset_index()\n",
    "del c_uk['index']\n",
    "c_uk['Daily_confirmed']=0\n",
    "i=0\n",
    "for i in range (len(c_uk.Confirmed)-1):\n",
    "    c_uk.Daily_confirmed.loc[i]=((c_uk['Confirmed'].loc[i]-c_uk['Confirmed'].loc[i+1]))\n",
    "c_uk\n",
    "    \n",
    "g= pd.merge(ftse,c_uk,on=['Date','Country'],how='outer')\n",
    "uk=g[g['Close'].notna()].fillna(0)\n",
    "\n",
    "#Merge dei dataframe\n",
    "merged_df = pd.concat([germany,canada,spain,india,france,australia,argentina,japan,us,china,russia,brazil,sk,italy,sa,turkey,uk], sort=True)\n",
    "index=merged_df.sort_values(by=['Date'],ascending=False).reset_index()\n",
    "index['Rate'] = index['Rate'].astype(float)\n",
    "del index['index']\n",
    "merged = index[['Country','Symbol','Date','Close','Rate','Confirmed','Daily_confirmed']]\n",
    "final = merged[merged['Close'].notna()].fillna(0).loc[1:1760].reset_index(drop=True)\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
